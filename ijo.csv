article_title;;section_title;;passage_text
Ingest Job Orchestrator;;S3 Ingestion;;Confluence team has built a data pipeline that continuously processes data from upstream data sources. We have onboarded to Horizon to help us manage EMR Clusters as well as facilitating getting data from EDX into our clusters. We have set up jobs that will automatically run when data for an upstream table is available, these jobs will create a dataset in S3 that contains the latest data from the upstream system. 
Ingest Job Orchestrator;;Problem statement;;Horizon is on the path of deprecation and it is no longer being able to provide the required support we need, we want to replace horizon with an alternative that is scalable and performs the functionalities which horizon did for us. These functionalities include notification and scheduled based trigering, job dependencies, ticketing, job retrying etc.
Ingest Job Orchestrator;;Tenets/Goals;;1.Consume OFA data from upstream service and load it into our S3 buckets 2. Build a orchestration system which auto backfills in case of delayed data from upstream or job failures 3. Minimize the overall end to end latency of getting data into our system 4. Minimize the amount of manual work required to kick start loading data into our system
Ingest Job Orchestrator;;Current Architecture;;In our existing architecture, we rely entirely on Horizon to kick off all of our jobs. The datasets from upstream are introduced in ten minute intervals. Every time that a new data segment comes in, Horizon will automatically kick off jobs for a group of tables that we are interested in, which is identified with a timestamp related to that data segment. All incoming data sets are processed in parallel across our EMR clusters. Rule Engine is a Scala package, which generates dynamic data transformation using Rule. This Rule is a template to generate dynamic queries for data transformation. For the generation of these queries, we extract Rule and table metadata information stored in Aurora Postgres. As we are generating queries for each execution, it provides our code adaptability for the changes in the source system. Additionally, these queries can run independently on different execution engine, When a job doesn't succeed a lambda re submits the job after logging the info in the DB.
Ingest Job Orchestrator;;proposed architecture;;The orchestration logic is triggered every ten minutes for every dataset using a eventbridge rule and step function orchestration performs a series of steps to submit the job to cradle and track the status of the submitted job. once the step function execution is completed a eventbridge rule triggers a lambda on state change of SFN, this lambda will make sure the status of dataset job is updated from "RUNNING" to a terminal state to avoid any infinite loops during SFN failures. The step function workflow is divided into following steps:
Ingest Job Orchestrator;;data model;;In order to properly submit jobs we have to keep track of the current status of dataset jobs and what data has been already processed until now. The majority of the data that we are storing is centered around a timestamped dataset so that will be the key identifier for our tables. 
Ingest Job Orchestrator;;Changes in current code;;To keep the scope of this project limited to deprecation of horizon, We are not trying to make too many changes in the way tier 1 executor layer is implemented. 
Ingest Job Orchestrator;;Ingest Layer Changes;;Updating the arguments passed to the job. 2. Updating the logic to fetch dataset name based on flowName and instead getting it from arguments. 3. For every timestamp range the job runs for, make entries for every ten minute segment in the message bus table.
Ingest Job Orchestrator;;Trade Off: Step Function vs AWS Batch;;The current approach to use step functions requires a state machine definition and 3 lambdas. The entire step function workflow can be reduced to have a single AWS Batch job definition and job queue. We have taken a calculated risk to go with Step Functions since
Ingest Job Orchestrator;;Trade Off: Step Function vs AWS Batch;;The lambdas are simple to write and deploy. Team has expertise on lambdas.
Ingest Job Orchestrator;;Trade Off: Step Function vs AWS Batch;;Lambdas have a current limitation to only execute a process for a maximum of 15 minutes before timing out which might be a issue if the lambda's wait for the jobs to complete to update the status.
Ingest Job Orchestrator;;Trade Off: Step Function vs AWS Batch;;Since Each job run on Batch will be run as a new ECS Task, meaning a new container for each job, this will add additional latency to our workflow. 
Ingest Job Orchestrator;;Trade Off: Step Function vs AWS Batch;;AWS Batch will add one more AWS service into the list of services the team needs to have knowledge/expertise of.
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;Airflow offers better visualizations which is one of the first reasons teams opt for it over Step Functions
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;For our use case we need to use wait state's in our orchestration which are provided natively in step functions and easy to plug and remove. 
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;Step functions provides API integrations with aws services like dynamo db, SQS, glue etc. to perform operations without using SDK code.
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;Airflow's Rest API is still experimental, while AWS Step Functions are supported by a range of production graded cli and SDK's.
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;Airflow has server costs while Step Functions have 4000/month free step executions (free tier) and $0.000025/step after that. e.g. if you use 10K steps for AWS Batch that run once daily, you will be priced $0.25 per day ($7.5 per month). The price for Airflow server (t2.large ec2 1 year reserved instance) is $41.98 per month. We will have to use AWS Batch for either case.
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;You can clear and rerun a failed task in Apache Airflow, but in Step Functions you will have to create a custom implementation to handle that. You may handle automated retries with back-offs in Step Functions definition as well.
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;Step Functions use easy to use JSON as state machine definition, while Airflow uses Python script.
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;Step Functions support async callbacks, i.e. state machine pauses until an external source notifies it to resume. While Airflow has yet to add this feature.
Ingest Job Orchestrator;;Trade-off: Step Function vs Apache Airflow;;Overall, I see more advantages of using AWS Step Functions. We will have to consider maintenance cost and development cost for both services as per our use case.
Ingest Job Orchestrator;;Scalability: Cradle;;Cradle manages the cluster's for us, so thereâ€™s no infrastructure to manage. We can scale up or down our existing jobs by changing the cluster type in job profiles
Ingest Job Orchestrator;;Scalability: Cradle;;Cradle WFR(Wait for resource) targets are thresholds set by BDT to help provide low, consistent WFR for your Cradle job runs. Cradle will proactively detect when they cannot meet these targets for us and take swift action to reduce WFR on your behalf.
Ingest Job Orchestrator;;Scalability: Cradle;;Customers usually need to specify their forecasted usage of the platform to help them beef up the resources and give customers more control over their billing and usage
Ingest Job Orchestrator;;Scalability: Step Functions;;Step Functions supports a fully serverless architecture and is highly scalable by nature. Most of the limits of the service are soft limits that can be increased via a ticket. We do have a hard limit of 25,000 events per State Machine execution. However, I don't expect that this will be a limit that we will hit.
Ingest Job Orchestrator;;Scalability: Dynamo Db;; Dynamo DB is highly scalable and there are examples of DDB tables that handle 7 million TPS. DDB is also widely used throughout Amazon so there are lots of resources of best practices as well as tweaks that we can make to make our table structure more performant. We are also only going to be querying rows in the table by using primary key and sort key, this should make look ups extremely quick.
Ingest Job Orchestrator;;Onboarding steps;;Step #1: Onboard dataset into confluence Use the stage_flow_name : `dummy` in json Follow the Dataset Onboarding Wiki to onboard dataset in confluence Verify the dataset_core_metadata, dataset_ext_metadata and dataset_column_metadata table in RDS. Validate if the dataset has onboarded successfully onboarded into the system Complete the snapshot and delta processing for the dataset before proceeding on incrementals 
Ingest Job Orchestrator;;Onboarding;;Step #2: Create cradle profile for dataset using the createCradleProfile API,Create the cradle profile by invoking the CreateCradleProfile API Sample input for dataset: ap_prepay_history_all and profileType: INCREMENTAL 3. Validate the Cradle profile
